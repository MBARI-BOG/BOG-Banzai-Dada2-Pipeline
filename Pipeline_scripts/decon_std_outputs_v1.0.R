#!/usr/bin/env Rscript

# RUN with Rscript decon_std_outputs_v1.0.R "${INPUT_ASV_TABLE}" "${METADATA}"


## Description
## This script is the first script run after running a plate through banzai/dada2. It takes the output from banzai/dada2, re-formats for further analysis (and for merging with other plates), 
## runs some decontamination scripts on the data, and produces some standard outputs (these are generated when this Rmd file is knit).

# The files generated by this script are an asv table and a taxonomy table, generated once for the raw data and once post-decontamination scripts.

## Load libraries
library(dplyr)
library(tidyverse)
library(ggplot2)
library(ggthemes)
library(cowplot)
library(gridExtra)

args = commandArgs(trailingOnly=TRUE)

input_asv_tax_table <- args[1]
input_metadata <- args[2]
output_dir <- args[3]
# Test file paths
print("Input_asv_tax_table")
print(input_asv_tax_table)
print("input_metadata")
print(input_metadata)
print("output_dir")
print(output_dir)


output_raw_asv_table_path <- paste0(output_dir, "/Filtered_raw_ASV_table.csv")
output_raw_tax_table_path <- paste0(output_dir, "/Filtered_raw_taxa_table.csv")
output_decon_asv_table_path <- paste0(output_dir, "/Filtered_decon_ASV_table.csv")
output_decon_tax_table_path <- paste0(output_dir, "/Filtered_decon_taxa_table.csv")



# Standard outputs

## Read counts
ASV_taxa_table <- read.csv(input_asv_tax_table, header = 1, stringsAsFactors = F)
ASV.table <- ASV_taxa_table %>% dplyr::select(-c(Kingdom,Phylum,Class,Order,Family,Genus,Species))
tax_table <- ASV_taxa_table[,c("ASV","Kingdom","Phylum","Class","Order","Family","Genus","Species")]
metadata <- read.csv(input_metadata, header = 1, stringsAsFactors = F)

read_counts <- as.data.frame(colSums(dplyr::select(ASV.table,-ASV)))
read_counts <- rownames_to_column(read_counts,"sample_name")
colnames(read_counts)[2] <- "sum_reads"

read_counts <- left_join(read_counts, dplyr::select(metadata, c(sample_name,sample_type)), by = "sample_name")

read_counts_gg <- ggplot(read_counts, aes(x = sample_name, y = sum_reads, color = sample_type))+
  geom_point()+
  theme(axis.text.x = element_text(angle = 90,size = 4))+
  ggtitle("Sample read sums")


## ASV counts
ASV_taxa_table <- read.csv(input_asv_tax_table, header = 1, stringsAsFactors = F)
ASV.table <- ASV_taxa_table %>% dplyr::select(-c(Kingdom,Phylum,Class,Order,Family,Genus,Species))
ASV_counts <- as.data.frame(colSums(dplyr::select(ASV.table,-ASV) != 0))
ASV_counts <- rownames_to_column(ASV_counts, "sample_name")
colnames(ASV_counts)[2] <- "nASVs"

ASV_counts <- left_join(ASV_counts, dplyr::select(metadata, c(sample_name,sample_type)), by = "sample_name")

ASV_counts_gg <- ggplot(ASV_counts, aes(x = sample_name, y = nASVs, color = sample_type))+
  geom_point()+
  theme(axis.text.x = element_text(angle = 90,size = 4))+
  ggtitle("Number of ASVs per sample")

## ASV counts by phylum
# Turn ASV table into table of detections - 1 for != 0, 0 for = 0.
ASV_det <- ASV.table
ASV_det[, 2:ncol(ASV_det)] <- ifelse(ASV_det[, 2:ncol(ASV_det)] == 0, 0, 1)

ASV_det <- left_join(ASV_det,tax_table, by = "ASV")

# Convert to long form
gathercols <- colnames(dplyr::select(ASV_taxa_table, -c(ASV,Kingdom,Phylum,Class,Order,Family,Genus,Species)))
ASV_det_long <- gather(ASV_det,gathercols, key = "sample", value = "nASVs")

ASV_det_phyla_gg <- ggplot(ASV_det_long, aes(x = sample, y = nASVs, fill = Phylum))+
  geom_bar(stat = "identity")+
  scale_fill_tableau(palette = "Tableau 20")+
  ggtitle("Top 20 Taxa")+
  guides(fill = guide_legend(title = "Phylum",ncol = 2))+
  theme(axis.text.x = element_text(angle = 90,size = 4))

ASV_det_phyla_legend <- get_legend(ASV_det_phyla_gg)

ASV_det_phyla_gg <- ggplot(ASV_det_long, aes(x = sample, y = nASVs, fill = Phylum))+
  geom_bar(stat = "identity")+
  scale_fill_tableau(palette = "Tableau 20")+
  ggtitle("ASVs by Phylum")+
  guides(fill = guide_legend(title = "Phylum",ncol = 2))+
  theme(axis.text.x = element_text(angle = 90,size = 4),
        legend.position = "none")


## Top 20 Phyla
ASV_taxa_table %>% dplyr::select(.,-c(Kingdom,Class,Order,Family,Genus,Species)) -> ASV_taxa_table_phylum
ASV_taxa_table_phylum %>% mutate(.,sum_reads = rowSums(dplyr::select(.,-c(ASV,Phylum)))) -> ASV_taxa_table_phylum_sums
ASV_taxa_table_phylum_sums %>% group_by(Phylum) %>% summarise(reads_by_Phylum = sum(sum_reads)) -> ASV_taxa_table_phylum_sums

# determine top 19 phyla, everything else becomes "other"
top19_Phylum <- ASV_taxa_table_phylum_sums[order(-ASV_taxa_table_phylum_sums$reads_by_Phylum),]$Phylum[1:19]
ASV_taxa_table_phylum %>% mutate(.,Phylum_new = ifelse(Phylum %in% top19_Phylum,Phylum,"Other")) -> ASV_taxa_table_phylum

# Convert to long form
gathercols <- colnames(dplyr::select(ASV_taxa_table, -c(ASV,Kingdom,Phylum,Class,Order,Family,Genus,Species)))
ASV_taxa_table_phylum_long <- gather(ASV_taxa_table_phylum,gathercols, key = "sample", value = "reads")

top_phyla_gg <- ggplot(ASV_taxa_table_phylum_long, aes(x = sample, y = reads, fill = Phylum_new))+
  geom_bar(stat = "identity")+
  scale_fill_tableau(palette = "Tableau 20")+
  ggtitle("Top 20 Phyla by Reads")+
  guides(fill = guide_legend(title = "Phylum",ncol = 2))+
  theme(axis.text.x = element_text(angle = 90,size = 4))

top_phyla_legend <- get_legend(top_phyla_gg)

top_phyla_gg <- ggplot(ASV_taxa_table_phylum_long, aes(x = sample, y = reads, fill = Phylum_new))+
  geom_bar(stat = "identity")+
  scale_fill_tableau(palette = "Tableau 20")+
  ggtitle("Top 20 Phyla")+
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 90,size = 4))

## Taxonomic composition (top 20 taxa)
ASV_taxa_table %>% unite("taxonomy", Kingdom:Phylum:Class:Order:Family:Genus:Species, sep = ":") -> ASV_taxa_table_concat
ASV_taxa_table_concat %>% mutate(.,sum_reads = rowSums(dplyr::select(.,-c(ASV,taxonomy)))) -> ASV_taxa_table_concat_sums
ASV_taxa_table_concat_sums %>% group_by(taxonomy) %>% summarise(reads_by_taxonomy = sum(sum_reads)) -> ASV_taxa_table_concat_sums

# determine top 19 taxonomic annotations, everything else becomes "other"
top19_taxonomy <- ASV_taxa_table_concat_sums[order(-ASV_taxa_table_concat_sums$reads_by_taxonomy),]$taxonomy[1:19]
ASV_taxa_table_concat %>% mutate(.,taxonomy_new = ifelse(taxonomy %in% top19_taxonomy,taxonomy,"Other")) -> ASV_taxa_table_concat

# Convert to long form
gathercols <- colnames(dplyr::select(ASV_taxa_table, -c(ASV,Kingdom,Phylum,Class,Order,Family,Genus,Species)))
ASV_taxa_table_concat_long <- gather(ASV_taxa_table_concat,gathercols, key = "sample", value = "reads")

top_taxa_gg <- ggplot(ASV_taxa_table_concat_long, aes(x = sample, y = reads, fill = taxonomy_new))+
  geom_bar(stat = "identity")+
  scale_fill_tableau(palette = "Tableau 20")+
  ggtitle("Top 20 Taxa")+
  guides(fill = guide_legend(title = "Taxonomy"))+
  theme(axis.text.x = element_text(angle = 90,size = 4))

top_taxa_legend <- get_legend(top_taxa_gg)

top_taxa_gg <- ggplot(ASV_taxa_table_concat_long, aes(x = sample, y = reads, fill = taxonomy_new))+
  geom_bar(stat = "identity")+
  scale_fill_tableau(palette = "Tableau 20")+
  ggtitle("Top 20 Taxa by Reads")+
  guides(fill = guide_legend(title = "Taxonomy"))+
  theme(legend.position = "none",
        axis.text.x = element_text(angle = 90,size = 4))

# Decontamination steps

#The decontamination code first detects and removes all singletons (ASVs with only a single read) from your dataset.

#The decontamination code then identifies all PCR blanks on your plate and identifies all ASVs that were found in your PCR blanks. For each ASV that was found in your PCR blanks, it then looks in all of your PCR blanks to find the maximum number of reads of that ASV that were found in any of your PCR blanks, and then subtracts this number of reads from all of the environmental samples.

#As an example, if you detected an ASV of *Homo sapiens* in two of your three PCR blanks, where the read counts in PCR blanks 1, 2 and 3 were 2, 0 and 18 respectively, it would then subtract 18 reads of that ASV of *Homo sapiens* from every environmental sample.

# I want this to output a standardized product, showing the number of reads/ASVs removed at each step, and the description of each step. Also standard plots and statistics
# Step_0: original data
# Step_1: singletons removed
# Step_2: any contamination found in pcr blanks removed

# Remove the taxonomy from the table and save it as an ASV table.
ASV_taxa_table <- read.csv(input_asv_tax_table, header = 1, stringsAsFactors = F)
ASV.table<- ASV_taxa_table %>% dplyr::select(-c(Kingdom,Phylum,Class,Order,Family,Genus,Species))
# Save the raw output
write_csv(ASV.table, output_raw_asv_table_path)

# ASV.table %>% ungroup() %>% dplyr::select(sample) %>% unique() %>% dim()

# Load metadata
metadata <- read.csv(input_metadata, header = 1, stringsAsFactors = F)

# Remove "Seq_number" , "sum.taxonomy", from the gathercols object. This way you will gather across only the samples.
gathercols <-  colnames(ASV.table)[colnames(ASV.table) != c("ASV")] 

# Convert to Long Data
ASV.table <- gather(ASV.table, sample, reads, gathercols, factor_key=TRUE)

#Rename Columns and remove seq_number (original description)
# We want to keep seq_number because we will use this to match to our tax_table that we created from the hashes
ASV.table %>%
  dplyr::mutate(Hash = as.character(ASV),
                sample = as.character(sample),
                nReads = reads) -> ASV.table
#  %>% dplyr::select(-Seq_number)  

## Create a summary function that adds results of each step

how.many <- function(ASVtable, round){
  ASVtable %>% ungroup() %>% 
    dplyr::summarise(nsamples = n_distinct(sample),
                     nASVs = n_distinct(Hash),
                     nReads = sum(nReads), 
                     Stage = paste0("Step_", round)) %>% 
    gather(starts_with("n"), value = "number", key = "Stat")
}

# Add your original, unmanipulated data here.
ASV.table %>% how.many(.,0) -> decontamination.summary0

# Remove singletons
ASV.table %>% 
  dplyr::group_by(ASV) %>% 
  dplyr::mutate (TotalReadsperSample = sum(reads)) %>% 
  filter(., TotalReadsperSample > 1) %>%
  dplyr::select(.,-TotalReadsperSample) -> ASV.table

# ASV.table %>% ungroup() %>% dplyr::select(sample) %>% unique() %>% dim()

#Remove empty sequences - this removes ~95% of all different ASVs. Lots of singletons!
ASV.table %>% 
  filter(reads != 0)  -> ASV.table

#Check if any samples are lost because there are no reads left
# ASV.table %>% ungroup() %>% dplyr::select(sample) %>% unique() %>% dim()

# Add the singleton removal step here to the decontamination.summary object
ASV.table %>% how.many(.,1) -> decontamination.summary1

decontamination.summary <- full_join(decontamination.summary0,decontamination.summary1)

# Identify postive controls, negative controls, and environmental samples
positives <- subset(metadata, sample_type %in% c("positive"))$sample_name
negatives <- subset(metadata, sample_type %in% c("negative"))$sample_name

## Estimates of contamination - just based on pcr blanks:
pcr_blanks <- as.list(grep("pcr", as.list(metadata$sample_name), value = TRUE))
ASV.table %>%
  dplyr::mutate(source = case_when(sample %in% pcr_blanks~"pcr_blanks", TRUE ~"Samples")) -> ASV.table

ASV.table %>%
  filter (source == "pcr_blanks") %>%
  group_by(Hash) %>%
  mutate(max_reads_in_pcr_blank = max(nReads)) -> pcr_blank_asvs

pcrblank_max_contam <- unique(pcr_blank_asvs[c("ASV","max_reads_in_pcr_blank")])


ASV.table %>% dplyr::group_by (sample) %>%
  left_join(.,pcrblank_max_contam, by = "ASV","sample") %>%
  mutate(updated_reads = ifelse(!is.na(max_reads_in_pcr_blank), nReads - max_reads_in_pcr_blank,nReads)) %>%
  mutate(reads = ifelse(updated_reads < 0, 0, updated_reads)) %>%
  filter(reads != 0)  %>%
  mutate(nReads = reads)-> ASV.table_cleaned


ASV.table_cleaned %>% how.many(.,2) -> decontamination.summary2
decontamination.summary <- full_join(decontamination.summary,decontamination.summary2)
decontamination.summary

## Write outputs:

ASV.table_cleaned %>%
  dplyr::select(-source,-Hash,-nReads,-max_reads_in_pcr_blank,-updated_reads) %>%
  spread(., key = "sample", value = "reads", fill = 0) -> ASV_sum.taxonomy

write_csv(ASV_sum.taxonomy, output_decon_asv_table_path)

## create the tax table
ASV_taxa_table <- read.csv(input_asv_tax_table, header = 1, stringsAsFactors = F)
tax_table <- ASV_taxa_table[,c("ASV","Kingdom","Phylum","Class","Order","Family","Genus","Species")]
write_csv(tax_table, output_decon_tax_table_path)
write_csv(tax_table, output_raw_tax_table_path)

#Step 0: original data

#Step 1: singletons removed

#Step 2: contamination found in pcr blanks removed. This step also removes the pcr blanks from your output ASV table file.


#### This table shows the top 20 ASVs that were found in the PCR blanks by read counts that were then removed from the environmental samples.

## Composition of PCR blanks
pcrblank_composition <- left_join(pcrblank_max_contam,tax_table, on = "ASV")
pcrblank_composition <- pcrblank_composition[order(-pcrblank_composition$max_reads_in_pcr_blank),]
pcrblank_composition %>% rename(reads_removed = max_reads_in_pcr_blank) -> pcrblank_composition
pcr_blank_table <- pcrblank_composition[1:20,]

## Save all plots as one PDF, as well as table of contaminants
pdf(paste0(output_dir,"/standard_outputs.pdf"), onefile = TRUE)

p <- list(read_counts_gg, ASV_counts_gg, ASV_det_phyla_gg, ASV_det_phyla_legend, top_phyla_gg, top_phyla_legend, top_taxa_gg,top_taxa_legend)
# p <- list(read_counts_gg, ASV_counts_gg, ASV_det_phyla_gg, ASV_det_phyla_legend, top_phyla_gg, top_phyla_legend, grid.arrange(top_taxa_gg,top_taxa_legend, ncol=1))
for (i in seq(length(p))) {
  do.call("grid.arrange", p[i])  
}
grid.arrange(top="Reads in PCR Blank Reads (removed during decontamination)", tableGrob(pcr_blank_table, theme = ttheme_default(base_size = 6)))
dev.off()
